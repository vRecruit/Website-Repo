{% extends "layout/layout_applicant.html" %}
{% block content %}

  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>

  <section id="intro">
    <div class="page-hero-section bg-image hero-home-2" style="background-image: url({{ url_for('static', filename='img/background-1/bg_hero_2.svg') }}">
      <div class="hero-caption">
        <div class="container fg-white h-100">
          <div class="row align-items-center h-100">
            <div class="col-lg-12">
                 <div class="row">
                 <div class="col-md-6">
                 <div style="position: relative; margin-left: -150px;   margin-top: 130px; " class="margin">
                   <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
                   <canvas id="overlay" />
                 </div>
                 </div>
                 <div class="col-md-6">
                   <div style="margin-top: 200px;" class="margin">
                    <div id="chatbox">
                        <div class="div-bot">
                         <p class="botText">Hi! I'm vRecruiter, your Interviewee today!</p>
                        </div>
                    </div>
                   </div>
                 </div>    
                 </div>
              </div>
            </div>
          </div>
        </div>
        </div>
    </section>

  <script>

    var threshold = 0.50
    let descriptors = { desc1: null, desc2: null }

    function updateResult() {
      const distance = faceapi.utils.round(
        faceapi.euclideanDistance(descriptors.desc1, descriptors.desc2)
      )
      let text = distance*100
      let bgColor = '#f5ffde'
      if (distance > threshold) {
        text += '% (no match)'
        bgColor = '#ce7575'
        console.log("Not Validated");
        alert("Face Does not match! Interview Paused");
      }else{
        text += '% (match)'
        console.log("Validated");
      }
      $('#distance').val(text)
      $('#distance').css('background-color', bgColor)
    }

    async function onSelectionChanged(which, uri) {
      const input = await faceapi.fetchImage(uri)
      const imgEl = $(`#face${which}`).get(0)
      imgEl.src = input.src
      descriptors[`desc${which}`] = await faceapi.computeFaceDescriptor(input)
    }

    async function onPlay() {
      const videoEl = $('#inputVideo').get(0)

      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())


      const options = getFaceDetectorOptions()

      const ts = Date.now()

      const result = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks()
      descriptors[`desc2`] = await faceapi.computeFaceDescriptor(videoEl,options)


      if (result) {
        const canvas = $('#overlay').get(0)
        const dims = faceapi.matchDimensions(canvas, videoEl, true)

        faceapi.draw.drawFaceLandmarks(canvas, faceapi.resizeResults(result, dims))
      }

      updateResult()

      setTimeout(() => onPlay())
    }

    async function run(src) {
      const MODEL_URL = '{{ url_for("static", filename="face/models") }}'
      await  faceapi.loadFaceRecognitionModel(MODEL_URL)
      await changeFaceDetector(TINY_FACE_DETECTOR)
      await faceapi.loadFaceLandmarkModel(MODEL_URL)
      $('#loader').hide()
      const input = await faceapi.fetchImage('{{ url_for("static", filename="face/img/face.jpeg") }}')
      descriptors[`desc1`] = await faceapi.computeFaceDescriptor(input)
      changeInputSize(128)
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream
      await onSelectionChanged(2, $('#selectList2 select').val())
      updateResult()
    }

    $(document).ready(function() {
      initFaceDetectionControls()
      run($('#face1').attr('src'))
    })

  </script>

 {% endblock content %}